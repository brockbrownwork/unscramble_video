{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd64027-c1ab-4740-87ce-35a8a74971b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter pixel positions (e.g., x1,y1;x2,y2;...):  0,0;1,1;2,2\n",
      "Enter frame numbers (e.g., 0,1,2,3,...):  0,1,2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grab_tvs(video_file):\n",
    "    positions_input = input(\"Enter pixel positions (e.g., x1,y1;x2,y2;...): \")\n",
    "    frames_input = input(\"Enter frame numbers (e.g., 0,1,2,3,...): \")\n",
    "\n",
    "    # Parse positions\n",
    "    positions = []\n",
    "    for pos in positions_input.strip().split(';'):\n",
    "        try:\n",
    "            x_str, y_str = pos.strip().split(',')\n",
    "            positions.append((int(x_str), int(y_str)))\n",
    "        except ValueError:\n",
    "            print(f\"Invalid position format: {pos}\")\n",
    "            return\n",
    "\n",
    "    # Parse frames\n",
    "    try:\n",
    "        frames = [int(f.strip()) for f in frames_input.strip().split(',')]\n",
    "    except ValueError:\n",
    "        print(\"Invalid frame numbers.\")\n",
    "        return\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    color_channels = 3  # Assuming BGR\n",
    "\n",
    "    # Validate frame numbers\n",
    "    frames = [f for f in frames if 0 <= f < total_frames]\n",
    "    if not frames:\n",
    "        print(\"No valid frame numbers provided.\")\n",
    "        return\n",
    "\n",
    "    # Validate positions\n",
    "    valid_positions = []\n",
    "    for x, y in positions:\n",
    "        if 0 <= x < frame_width and 0 <= y < frame_height:\n",
    "            valid_positions.append((x, y))\n",
    "        else:\n",
    "            print(f\"Invalid position ({x}, {y}) - outside frame dimensions.\")\n",
    "    if not valid_positions:\n",
    "        print(\"No valid pixel positions provided.\")\n",
    "        return\n",
    "\n",
    "    positions = valid_positions\n",
    "\n",
    "    # Prepare output array\n",
    "    num_positions = len(positions)\n",
    "    num_frames = len(frames)\n",
    "    output_array = np.zeros((num_positions, num_frames * color_channels), dtype=np.uint8)\n",
    "\n",
    "    # For memory efficiency, process one frame at a time\n",
    "    for frame_idx, frame_number in enumerate(frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Error reading frame {frame_number}.\")\n",
    "            continue\n",
    "\n",
    "        for pos_idx, (x, y) in enumerate(positions):\n",
    "            color = frame[y, x, :]  # Note that frame[y, x] gives BGR color\n",
    "            output_array[pos_idx, frame_idx*color_channels:(frame_idx+1)*color_channels] = color\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return output_array\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tvs = grab_tvs(\"cab_ride_trimmed.mkv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b556aaa6-528d-4f95-823c-8d621759a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217 174 131 217 174 131 217 174 131]\n",
      " [218 175 132 218 175 132 218 175 132]\n",
      " [218 175 132 218 175 132 218 175 132]]\n"
     ]
    }
   ],
   "source": [
    "print(tvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae4bcfe-79fd-4e8f-91a4-36bb545aaed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([217, 174, 131, 217, 174, 131, 217, 174, 131], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c16971-47aa-4146-832a-5fb2e5c80ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b8ada1-1133-4cdb-b5a0-6eed6a3823d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e120d7ed-44e0-4407-96c6-fe3124f56cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6ca88e-ce00-419d-b3ee-6ae8680eb773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296b9384-4672-4944-b4a8-fb5256849712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([217, 174, 131, 217, 174, 131, 217, 174, 131], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62034490-7d29-4ad1-820e-8b6825ca2ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([218, 175, 132, 218, 175, 132, 218, 175, 132], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a4243e-3d88-438c-a72a-3f83fab2b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([218, 175, 132, 218, 175, 132, 218, 175, 132], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f54b8-0cba-480f-966e-0d90245f83ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
