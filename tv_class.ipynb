{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20db3286-c462-4557-8fc8-ca6e908d349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb0e04b-3122-402a-858b-857f7e38320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV(original_position=(50, 50), num_frames=6)\n",
      "Color at frame 20 for position (50, 50): [139 181 227]\n",
      "TV(original_position=(100, 100), num_frames=6)\n",
      "Color at frame 20 for position (100, 100): [141 185 230]\n",
      "TV(original_position=(150, 150), num_frames=6)\n",
      "Color at frame 20 for position (150, 150): [149 194 236]\n",
      "TV at position (50, 50):\n",
      "  Frame 0: [137 182 224]\n",
      "  Frame 10: [137 182 224]\n",
      "  Frame 20: [139 181 227]\n",
      "  Frame 30: [139 181 227]\n",
      "  Frame 40: [139 181 229]\n",
      "  Frame 50: [141 185 232]\n",
      "TV at position (100, 100):\n",
      "  Frame 0: [139 186 230]\n",
      "  Frame 10: [139 186 230]\n",
      "  Frame 20: [141 185 230]\n",
      "  Frame 30: [142 186 231]\n",
      "  Frame 40: [144 188 235]\n",
      "  Frame 50: [148 192 239]\n",
      "TV at position (150, 150):\n",
      "  Frame 0: [148 193 235]\n",
      "  Frame 10: [149 194 236]\n",
      "  Frame 20: [149 194 236]\n",
      "  Frame 30: [149 194 236]\n",
      "  Frame 40: [151 195 240]\n",
      "  Frame 50: [152 196 241]\n"
     ]
    }
   ],
   "source": [
    "class TV:\n",
    "    def __init__(self, original_position, frame_numbers, color_series):\n",
    "        \"\"\"\n",
    "        Initialize a TV instance.\n",
    "\n",
    "        :param original_position: Tuple[int, int] representing (x, y) coordinates.\n",
    "        :param frame_numbers: List[int], list of frame indices.\n",
    "        :param color_series: NumPy array of shape (len(frame_numbers), 3) representing RGB colors.\n",
    "        \"\"\"\n",
    "        self.original_position = original_position\n",
    "        self.current_position = original_position\n",
    "        self.frame_numbers = frame_numbers\n",
    "        self.color_series = color_series  # Shape: (len(frame_numbers), 3)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieve the color at a specific frame number.\n",
    "\n",
    "        :param index: int, the frame number.\n",
    "        :return: Tuple[int, int, int] representing the RGB color.\n",
    "        \"\"\"\n",
    "        return self.color_series[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of frames in the color series.\n",
    "\n",
    "        :return: int\n",
    "        \"\"\"\n",
    "        return len(self.color_series)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"TV(original_position={self.original_position}, \"\n",
    "                f\"num_frames={len(self.color_series)})\")\n",
    "\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, video_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the VideoProcessor by setting the video path and retrieving video dimensions.\n",
    "\n",
    "        :param video_path: str, path to the video file.\n",
    "        \"\"\"\n",
    "        self.video_path = video_path\n",
    "        self.width = None\n",
    "        self.height = None\n",
    "        self._retrieve_video_dimensions()\n",
    "\n",
    "    def _retrieve_video_dimensions(self):\n",
    "        \"\"\"\n",
    "        Retrieve and store the width and height of the video.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video file {self.video_path}\")\n",
    "\n",
    "        # Retrieve width and height\n",
    "        self.width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        if self.width == 0 or self.height == 0:\n",
    "            # Fallback: read the first frame to get dimensions\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                raise IOError(f\"Cannot read frames to determine video dimensions for {self.video_path}\")\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            self.height, self.width, _ = frame_rgb.shape\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def create_tvs(self, positions: List[Tuple[int, int]], frame_numbers: List[int] = None) -> List[TV]:\n",
    "        \"\"\"\n",
    "        Create multiple TV instances for a list of pixel positions.\n",
    "\n",
    "        :param positions: List[Tuple[int, int]] representing (x, y) coordinates.\n",
    "        :param frame_numbers: List[int], list of frame indices to include. Defaults to all frames.\n",
    "        :return: List[TV] instances.\n",
    "        \"\"\"\n",
    "        # Validate positions against video dimensions\n",
    "        for pos in positions:\n",
    "            x, y = pos\n",
    "            if not (0 <= x < self.width and 0 <= y < self.height):\n",
    "                raise ValueError(f\"Position {pos} is out of bounds for frame size ({self.width}, {self.height}).\")\n",
    "\n",
    "        # Initialize data structures for each position\n",
    "        tvs_data = {pos: {'frame_numbers': [], 'color_series': []} for pos in positions}\n",
    "\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video file {self.video_path}\")\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if frame_numbers is None:\n",
    "            frame_numbers = list(range(total_frames))\n",
    "        else:\n",
    "            # Validate frame numbers\n",
    "            for fn in frame_numbers:\n",
    "                if not (0 <= fn < total_frames):\n",
    "                    raise ValueError(f\"Frame number {fn} is out of bounds for number of frames {total_frames}.\")\n",
    "\n",
    "        # Process specified frames\n",
    "        for frame_idx in frame_numbers:\n",
    "            # Set the position of the next frame to be read\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                raise IOError(f\"Failed to read frame {frame_idx} from video.\")\n",
    "\n",
    "            # Convert frame from BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for pos in positions:\n",
    "                x, y = pos\n",
    "                color = frame_rgb[y, x, :]  # Shape: (3,)\n",
    "                tvs_data[pos]['frame_numbers'].append(frame_idx)\n",
    "                tvs_data[pos]['color_series'].append(color)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Create TV instances\n",
    "        tv_instances = []\n",
    "        for pos in positions:\n",
    "            frames = tvs_data[pos]['frame_numbers']\n",
    "            colors = np.array(tvs_data[pos]['color_series'])\n",
    "            tv = TV(original_position=pos, frame_numbers=frames, color_series=colors)\n",
    "            tv_instances.append(tv)\n",
    "\n",
    "        return tv_instances\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    video_path = 'cab_ride_trimmed.mkv'  # Replace with your video file path\n",
    "    processor = VideoProcessor(video_path)\n",
    "\n",
    "    # Define pixel positions you want to track\n",
    "    pixel_positions = [\n",
    "        (50, 50),\n",
    "        (100, 100),\n",
    "        (150, 150),\n",
    "        # Add more positions as needed\n",
    "    ]\n",
    "\n",
    "    # Define specific frame numbers you want to process\n",
    "    specific_frame_numbers = [0, 10, 20, 30, 40, 50]  # Example frame numbers\n",
    "\n",
    "    # Create TV instances for these positions with specific frame numbers\n",
    "    tvs = processor.create_tvs(pixel_positions, frame_numbers=specific_frame_numbers)\n",
    "\n",
    "    # Example: Accessing color series\n",
    "    for tv in tvs:\n",
    "        print(tv)\n",
    "        # Get color at frame number 20\n",
    "        try:\n",
    "            idx = tv.frame_numbers.index(20)\n",
    "            color = tv.color_series[idx]\n",
    "            print(f\"Color at frame 20 for position {tv.original_position}: {color}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Frame 20 not found in TV at position {tv.original_position}.\")\n",
    "\n",
    "    # Example: Iterate over all TVs and their color series\n",
    "    for tv in tvs:\n",
    "        print(f\"TV at position {tv.original_position}:\")\n",
    "        for i, color in enumerate(tv.color_series):\n",
    "            frame_number = tv.frame_numbers[i]\n",
    "            print(f\"  Frame {frame_number}: {color}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fb08b-4fc8-4fc4-a3de-2333ab0e50aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
