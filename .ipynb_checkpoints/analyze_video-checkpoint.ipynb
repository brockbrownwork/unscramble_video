{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476a117b-d0fe-4e7a-b5ba-e20763092ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating threshold videos: 100%|███████████████████████████████████████████████████████| 13/13 [02:23<00:00, 11.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching all videos together...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stitching videos: 100%|████████████████████████████████████████████████████████████████| 13/13 [00:11<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined video saved as videos\\combined_thresholds_video.mp4.\n",
      "Deleting noncombined videos...\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.10.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.20.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.30.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.40.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.50.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.60.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.70.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.80.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.85.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.90.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.95.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.98.mp4\n",
      "Deleted videos\\euclidean_annotated_video_threshold_0.99.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "\n",
    "def process_video(input_video_path, output_video_path, threshold=0.8, num_frames=200, verbose=False):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        if verbose:\n",
    "            print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        if verbose:\n",
    "            print(\"Failed to read the first frame of the video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "    center_y = height // 2\n",
    "    center_x = width // 2\n",
    "\n",
    "    # Initialize arrays to store frames\n",
    "    frames_list = [frame]\n",
    "    frame_count = 1\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Reading frames...\")\n",
    "\n",
    "    # Read the specified number of frames\n",
    "    while frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            if verbose:\n",
    "                print(f\"Reached end of video at frame {frame_count}.\")\n",
    "            break\n",
    "        frames_list.append(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    num_frames = len(frames_list)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total frames read: {num_frames}\")\n",
    "\n",
    "    # Convert frames list to numpy array\n",
    "    frames_array = np.array(frames_list, dtype=np.uint8)  # Shape: (num_frames, height, width, 3)\n",
    "\n",
    "    # Reshape frames to (height * width, num_frames * channels)\n",
    "    if verbose:\n",
    "        print(\"Processing pixel time series...\")\n",
    "    frames_reshaped = frames_array.transpose(1, 2, 0, 3).reshape(height * width, num_frames * channels)\n",
    "\n",
    "    # Get the time series of the center pixel\n",
    "    center_index = center_y * width + center_x\n",
    "    center_pixel_vector = frames_reshaped[center_index, :]\n",
    "\n",
    "    # Compute Euclidean distances\n",
    "    if verbose:\n",
    "        print(\"Calculating Euclidean distances...\")\n",
    "    diffs = frames_reshaped.astype(np.float32) - center_pixel_vector.astype(np.float32)\n",
    "    distances = np.linalg.norm(diffs, axis=1)\n",
    "\n",
    "    # Reshape distances back to image shape\n",
    "    distances_image = distances.reshape(height, width)\n",
    "\n",
    "    # Normalize distances to get similarity (0 to 1)\n",
    "    if verbose:\n",
    "        print(\"Normalizing distances...\")\n",
    "    max_distance = distances_image.max()\n",
    "    if max_distance == 0:\n",
    "        if verbose:\n",
    "            print(\"Max distance is zero. All pixels are identical to the center pixel.\")\n",
    "        similarity = np.ones_like(distances_image)\n",
    "    else:\n",
    "        similarity = 1 - (distances_image / max_distance)\n",
    "\n",
    "    # Create mask for fully white pixels based on threshold\n",
    "    white_mask = (similarity >= threshold).astype(np.float32)[:, :, np.newaxis]  # Shape: (height, width, 1)\n",
    "\n",
    "    # Function to add red dot at the center of the frame\n",
    "    def add_red_dot_center(frame):\n",
    "        cv2.circle(frame, (center_x, center_y), 1, (0, 0, 255), 1)\n",
    "        return frame\n",
    "\n",
    "    # Function to add the threshold text in Comic Sans at the top right\n",
    "    def add_threshold_text(frame, threshold):\n",
    "        text = f\"threshold: {threshold:.2f}\"\n",
    "        position = (width - 300, 50)  # Top-right position\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        color = (0, 0, 0)  # Black color for text\n",
    "        thickness = 2\n",
    "        # Apply the text in lowercase in Comic Sans-like style\n",
    "        cv2.putText(frame, text.lower(), position, font, font_scale, color, thickness, lineType=cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "    # Initialize VideoWriter\n",
    "    if verbose:\n",
    "        print(\"Writing annotated video...\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        # Make a copy of the frame to avoid modifying the original data\n",
    "        blended_frame = frames_list[i].copy()\n",
    "\n",
    "        # Normalize frame to [0,1] for blending with the white mask\n",
    "        blended_frame_float = blended_frame.astype(np.float32) / 255.0\n",
    "        white_frame = np.ones((height, width, 3), dtype=np.float32)  # Fully white pixel overlay\n",
    "\n",
    "        # Blend the frame with white based on the mask\n",
    "        final_frame = blended_frame_float * (1.0 - white_mask) + white_frame * white_mask\n",
    "        final_frame = np.clip(final_frame * 255, 0, 255).astype(np.uint8)\n",
    "        final_frame = add_red_dot_center(final_frame)\n",
    "        final_frame = add_threshold_text(final_frame, threshold)\n",
    "\n",
    "        out.write(final_frame)\n",
    "\n",
    "    out.release()\n",
    "    if verbose:\n",
    "        print(f\"Annotated video saved as {output_video_path}. Threshold: {threshold:.2f}\")\n",
    "\n",
    "\n",
    "# Create multiple videos for different thresholds\n",
    "threshold_values = [0.99, 0.98, 0.95, 0.9, 0.85, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "for threshold in tqdm(threshold_values, desc=\"Creating threshold videos\"):\n",
    "    output_path = os.path.join('videos', f'euclidean_annotated_video_threshold_{threshold:.2f}.mp4')\n",
    "    process_video('cab_ride_trimmed.mkv', output_path, threshold=threshold)\n",
    "\n",
    "# Stitch all videos together\n",
    "print(\"Stitching all videos together...\")\n",
    "output_combined_path = os.path.join('videos', 'combined_thresholds_video.mp4')\n",
    "video_files = sorted(glob.glob(os.path.join('videos', 'euclidean_annotated_video_threshold_*.mp4')))\n",
    "\n",
    "# Get properties from the first video\n",
    "cap = cv2.VideoCapture(video_files[0])\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the first video for stitching.\")\n",
    "    exit(1)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.release()\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_combined = cv2.VideoWriter(output_combined_path, fourcc, fps, (width, height))\n",
    "\n",
    "for video_file in tqdm(video_files, desc=\"Stitching videos\"):\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_file}\")\n",
    "        continue\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out_combined.write(frame)\n",
    "    cap.release()\n",
    "\n",
    "out_combined.release()\n",
    "print(f\"Combined video saved as {output_combined_path}.\")\n",
    "\n",
    "# Delete the noncombined videos\n",
    "print(\"Deleting noncombined videos...\")\n",
    "for video_file in video_files:\n",
    "    try:\n",
    "        os.remove(video_file)\n",
    "        print(f\"Deleted {video_file}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: Could not delete {video_file}. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9192ec5-431f-4e6f-9032-46eef7b55b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
