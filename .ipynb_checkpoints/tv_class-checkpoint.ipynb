{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20db3286-c462-4557-8fc8-ca6e908d349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb0e04b-3122-402a-858b-857f7e38320c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTV(original_position=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_position\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mVideoProcessor\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250;43m        \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;43;03m        Initialize the VideoProcessor by setting the video path and retrieving video dimensions.\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;43;03m        :param video_path: str, path to the video file.\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;43;03m        \"\"\"\u001b[39;49;00m\n",
      "Cell \u001b[1;32mIn[3], line 72\u001b[0m, in \u001b[0;36mVideoProcessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth, _ \u001b[38;5;241m=\u001b[39m frame_rgb\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     70\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tvs\u001b[39m(\u001b[38;5;28mself\u001b[39m, positions: \u001b[43mList\u001b[49m[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]], frame_numbers: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[TV]:\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    Create multiple TV instances for a list of pixel positions.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    :return: List[TV] instances.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Validate positions against video dimensions\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "class TV:\n",
    "    def __init__(self, original_position, frame_numbers, color_series):\n",
    "        \"\"\"\n",
    "        Initialize a TV instance.\n",
    "\n",
    "        :param original_position: Tuple[int, int] representing (x, y) coordinates.\n",
    "        :param frame_numbers: List[int], list of frame indices.\n",
    "        :param color_series: NumPy array of shape (len(frame_numbers), 3) representing RGB colors.\n",
    "        \"\"\"\n",
    "        self.original_position = original_position\n",
    "        self.current_position = original_position\n",
    "        self.frame_numbers = frame_numbers\n",
    "        self.color_series = color_series  # Shape: (len(frame_numbers), 3)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieve the color at a specific frame number.\n",
    "\n",
    "        :param index: int, the frame number.\n",
    "        :return: Tuple[int, int, int] representing the RGB color.\n",
    "        \"\"\"\n",
    "        return self.color_series[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of frames in the color series.\n",
    "\n",
    "        :return: int\n",
    "        \"\"\"\n",
    "        return len(self.color_series)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"TV(original_position={self.original_position}, \"\n",
    "                f\"num_frames={len(self.color_series)})\")\n",
    "\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, video_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the VideoProcessor by setting the video path and retrieving video dimensions.\n",
    "\n",
    "        :param video_path: str, path to the video file.\n",
    "        \"\"\"\n",
    "        self.video_path = video_path\n",
    "        self.width = None\n",
    "        self.height = None\n",
    "        self._retrieve_video_dimensions()\n",
    "\n",
    "    def _retrieve_video_dimensions(self):\n",
    "        \"\"\"\n",
    "        Retrieve and store the width and height of the video.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video file {self.video_path}\")\n",
    "\n",
    "        # Retrieve width and height\n",
    "        self.width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        if self.width == 0 or self.height == 0:\n",
    "            # Fallback: read the first frame to get dimensions\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                raise IOError(f\"Cannot read frames to determine video dimensions for {self.video_path}\")\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            self.height, self.width, _ = frame_rgb.shape\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    def create_tvs(self, positions: List[Tuple[int, int]], frame_numbers: List[int] = None) -> List[TV]:\n",
    "        \"\"\"\n",
    "        Create multiple TV instances for a list of pixel positions.\n",
    "\n",
    "        :param positions: List[Tuple[int, int]] representing (x, y) coordinates.\n",
    "        :param frame_numbers: List[int], list of frame indices to include. Defaults to all frames.\n",
    "        :return: List[TV] instances.\n",
    "        \"\"\"\n",
    "        # Validate positions against video dimensions\n",
    "        for pos in positions:\n",
    "            x, y = pos\n",
    "            if not (0 <= x < self.width and 0 <= y < self.height):\n",
    "                raise ValueError(f\"Position {pos} is out of bounds for frame size ({self.width}, {self.height}).\")\n",
    "\n",
    "        # Initialize data structures for each position\n",
    "        tvs_data = {pos: {'frame_numbers': [], 'color_series': []} for pos in positions}\n",
    "\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Cannot open video file {self.video_path}\")\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if frame_numbers is None:\n",
    "            frame_numbers = list(range(total_frames))\n",
    "        else:\n",
    "            # Validate frame numbers\n",
    "            for fn in frame_numbers:\n",
    "                if not (0 <= fn < total_frames):\n",
    "                    raise ValueError(f\"Frame number {fn} is out of bounds for number of frames {total_frames}.\")\n",
    "\n",
    "        # Process specified frames\n",
    "        for frame_idx in frame_numbers:\n",
    "            # Set the position of the next frame to be read\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                raise IOError(f\"Failed to read frame {frame_idx} from video.\")\n",
    "\n",
    "            # Convert frame from BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for pos in positions:\n",
    "                x, y = pos\n",
    "                color = frame_rgb[y, x, :]  # Shape: (3,)\n",
    "                tvs_data[pos]['frame_numbers'].append(frame_idx)\n",
    "                tvs_data[pos]['color_series'].append(color)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Create TV instances\n",
    "        tv_instances = []\n",
    "        for pos in positions:\n",
    "            frames = tvs_data[pos]['frame_numbers']\n",
    "            colors = np.array(tvs_data[pos]['color_series'])\n",
    "            tv = TV(original_position=pos, frame_numbers=frames, color_series=colors)\n",
    "            tv_instances.append(tv)\n",
    "\n",
    "        return tv_instances\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    video_path = 'cab_ride_trimmed.mkv'  # Replace with your video file path\n",
    "    processor = VideoProcessor(video_path)\n",
    "\n",
    "    # Define pixel positions you want to track\n",
    "    pixel_positions = [\n",
    "        (50, 50),\n",
    "        (100, 100),\n",
    "        (150, 150),\n",
    "        # Add more positions as needed\n",
    "    ]\n",
    "\n",
    "    # Define specific frame numbers you want to process\n",
    "    specific_frame_numbers = [0, 10, 20, 30, 40, 50]  # Example frame numbers\n",
    "\n",
    "    # Create TV instances for these positions with specific frame numbers\n",
    "    tvs = processor.create_tvs(pixel_positions, frame_numbers=specific_frame_numbers)\n",
    "\n",
    "    # Example: Accessing color series\n",
    "    for tv in tvs:\n",
    "        print(tv)\n",
    "        # Get color at frame number 20\n",
    "        try:\n",
    "            idx = tv.frame_numbers.index(20)\n",
    "            color = tv.color_series[idx]\n",
    "            print(f\"Color at frame 20 for position {tv.original_position}: {color}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Frame 20 not found in TV at position {tv.original_position}.\")\n",
    "\n",
    "    # Example: Iterate over all TVs and their color series\n",
    "    for tv in tvs:\n",
    "        print(f\"TV at position {tv.original_position}:\")\n",
    "        for i, color in enumerate(tv.color_series):\n",
    "            frame_number = tv.frame_numbers[i]\n",
    "            print(f\"  Frame {frame_number}: {color}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fb08b-4fc8-4fc4-a3de-2333ab0e50aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
